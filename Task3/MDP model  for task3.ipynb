{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------------------TASK3--------------------------------\"\"\"\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def write_in_pickle(data, path):\n",
    "    \"\"\"\n",
    "    Write data into a file formed by pickle.\n",
    "    \"\"\"\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "\n",
    "def load_pickle(path):\n",
    "    \"\"\"\n",
    "    Load data from a file formed by pickle.\n",
    "    Return the data in the form of original.\n",
    "    \"\"\"\n",
    "    pkl_file = open(path, 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data\n",
    "\n",
    "def load_json(dir):\n",
    "    \"\"\"\n",
    "    Load the json data and return. \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(dir, 'r') as f:\n",
    "        while True:\n",
    "            a = f.readline()\n",
    "            if not a:\n",
    "                break\n",
    "            b = json.loads(a)\n",
    "            data.append(b)\n",
    "    return data\n",
    "\n",
    "# Get all papers from allpaper.txt\n",
    "papers = load_json('/Users/zhengwei/Desktop/allpaper.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate the cooperations directionary and save in file in form of pickle.\n",
    "{key: author name, value: a list [c1_name, c2_name, ...]}\n",
    "\"\"\"\n",
    "cooperation_authors = {}\n",
    "for paper in papers:\n",
    "    if paper[\"year\"] > 2012:\n",
    "        continue\n",
    "    for author in paper[\"authors\"]:\n",
    "        if author not in cooperation_authors:\n",
    "            cooperation_authors[author] = []\n",
    "        for author_coor in paper[\"authors\"]:\n",
    "            if author_coor != author and author_coor not in cooperation_authors[author]:\n",
    "                cooperation_authors[author].append(author_coor)\n",
    "write_in_pickle(cooperation_authors, \"/Users/zhengwei/Desktop/coor_author.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate two dictionnary big_dict and end_dic.\n",
    "big_dict: {key: the name of conference, value: [id1, id2, ...]}\n",
    "end_dic: {key: the name of author, value: {key: year, value: a dim-length list, dim is the\n",
    "          number of conferences and each item takes 0 or 1, 1: appear, 0: nope}}\n",
    "\"\"\"\n",
    "import os\n",
    "import copy\n",
    "\n",
    "file_dir = (\"/Users/zhengwei/Desktop/all/社交网络挖掘/social_network/papers/\")\n",
    "file_list = [files for root, dirs, files in os.walk(file_dir)][0]\n",
    "big_dict = {}\n",
    "end_dic = {}\n",
    "for item in file_list:\n",
    "    temp_file = load_json(file_dir + item)\n",
    "    domain = item[:item.index('.')]\n",
    "\n",
    "    big_dict[domain] = []\n",
    "    for entry in temp_file:\n",
    "        big_dict[domain].append(entry[\"id\"])\n",
    "\n",
    "domain_list = list(big_dict.keys())\n",
    "year = [i for i in range(1965, 2018)]\n",
    "init_vec = [[0]*len(domain_list) for i in range(len(year))]\n",
    "init_dic = dict(zip(year, init_vec))\n",
    "for paper in papers:\n",
    "    domain_index = -1\n",
    "    paper_id = paper[\"id\"]\n",
    "    for i in range(len(domain_list)):\n",
    "        if paper_id in big_dict[domain_list[i]]:\n",
    "            domain_index = i\n",
    "            break\n",
    "    for author in paper[\"authors\"]:\n",
    "        if author not in end_dic:\n",
    "            end_dic[author] = copy.deepcopy(init_dic)\n",
    "        end_dic[author][paper[\"year\"]][domain_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the transfer matrix of order dimension, order stands for previous years.\n",
    "Part the data into train dataset and test dataset, taking the 2012 as the boundary.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "order = 10\n",
    "tran_matrix = {}\n",
    "dim = len(domain_list)\n",
    "for author in end_dic:\n",
    "    tran_matrix[author] = [[[0,0,0,0] for j in range(dim)]for i in range(dim)]  # (1->1, 1->0, 0->1, 0->0)\n",
    "    first_paper = 1\n",
    "    old_year_data = []\n",
    "    for year, new_year_data in end_dic[author].items():\n",
    "        if year > 2012:\n",
    "            break\n",
    "        if first_paper:\n",
    "            if sum(new_year_data):\n",
    "                continue\n",
    "            else:\n",
    "                first_paper = 0\n",
    "                year_grep = 1\n",
    "                old_year_data.append(new_year_data)\n",
    "                continue\n",
    "        if len(old_year_data) < 10:\n",
    "            old_year_data.append(new_year_data)\n",
    "            if year < 2012:\n",
    "                continue\n",
    "        five_year_data = np.array(old_year_data).sum(axis=0)\n",
    "        for i in range(len(five_year_data)):\n",
    "            data1 = five_year_data[i]\n",
    "            for j in range(len(new_year_data)):\n",
    "                data2 = new_year_data[j]\n",
    "                if data1:\n",
    "                    if data2:\n",
    "                        tran_matrix[author][i][j][0] += 1\n",
    "                    else:\n",
    "                        tran_matrix[author][i][j][1] += 1\n",
    "                else:\n",
    "                    if data2:\n",
    "                        tran_matrix[author][i][j][2] += 1\n",
    "                    else:\n",
    "                        tran_matrix[author][i][j][3] += 1\n",
    "        old_year_data.append(new_year_data)\n",
    "        old_year_data = old_year_data[1:]\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            temp = tran_matrix[author][i][j]\n",
    "            tran_matrix[author][i][j] = [temp[0]/(temp[0] + temp[1] + 1e-10), temp[2]/(temp[2] + temp[3] + 1e-10)]\n",
    "write_in_pickle(tran_matrix, \"/Users/zhengwei/Desktop/transfer_matrix_10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Employ the MDP model into the train dataset to compare the test dataset and the predicted result.\n",
    "Calculate the accuracy, precision, recall and F1-score for two issues: \n",
    "one is whether an author will appear a paper next year, the other is whether the paper will hit the conference. \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "dim = 21\n",
    "end_result = {}\n",
    "for year in range(2013, 2018):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    TP1 = 0\n",
    "    FP1 = 0\n",
    "    TN1 = 0\n",
    "    FN1 = 0\n",
    "    for author in end_dic:\n",
    "        test_vec = end_dic[author][year]\n",
    "        train_vec = list(np.array([end_dic[author][i] for i in range(year-10,year)]).sum(axis=0))\n",
    "        predict_vec = [0] * dim\n",
    "        for col in range(dim):\n",
    "            temp_vec = np.array(tran_matrix[author])[:,col]\n",
    "            for i in range(dim):\n",
    "                if i == col:\n",
    "                    predict_vec[col] += (temp_vec[i][0] if train_vec[i] else temp_vec[i][1]) * 0.9 * 3\n",
    "                else:\n",
    "                    predict_vec[col] += (temp_vec[i][0] if train_vec[i] else temp_vec[i][1]) * 0.005 * 3\n",
    "        predict_vec = [0 + int(item > 0.5) for item in predict_vec]\n",
    "        expected = sum(test_vec)\n",
    "        predicted = sum(predict_vec)\n",
    "        if expected:\n",
    "            if predicted:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if predicted:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "\n",
    "        for i in range(dim):\n",
    "            expected_v = test_vec[i]\n",
    "            predicted_v = predict_vec[i]\n",
    "            if expected_v:\n",
    "                if predicted_v:\n",
    "                    TP1 += 1\n",
    "                else:\n",
    "                    FN1 += 1\n",
    "            else:\n",
    "                if predicted_v:\n",
    "                    FP1 += 1\n",
    "                else:\n",
    "                    TN1 += 1\n",
    "    result = [[0,0,0,0],[0,0,0,0]]\n",
    "    result[0][0] = (TP + FN)/(TP + TN + FP + FN)\n",
    "    result[0][1] = TP/(TP + FP)\n",
    "    result[0][2] = TP/(TP + FN)\n",
    "    result[0][3] = 2/(1/result[0][1] + 1/result[0][2])\n",
    "    result[1][0] = (TP1 + TN1)/(TP1 + TN1 + FP1 + FN1)\n",
    "    result[1][1] = TP1/(TP1 + FP1)\n",
    "    result[1][2] = TP1/(TP1 + FN1)\n",
    "    result[1][3] = 2/(1/result[1][1] + 1/result[1][2])\n",
    "    end_result[year] = result\n",
    "write_in_pickle(end_result, \"/Users/zhengwei/Desktop/end_result_10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
